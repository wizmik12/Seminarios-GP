{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seminarios de Procesos Gaussianos\n",
    "\n",
    "### Grupo de procesamiento de la información visual (VIP) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> Miguel López Pérez </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Librerías a usar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los ejemplos de estos notebooks van a estar basados en la librería gpflow. Es una extensión de GPy con la ventaja \n",
    "de que se pueden cargar cálculos en la GPU al estar basado en tensorflow. Al ser un proyecto open source podemos acceder a su [documentación](https://gpflow.readthedocs.io/en/develop/intro.html) y [código](https://github.com/GPflow/GPflow/tree/master). También nos hará falta tener instalada la librería scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpflow\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import tensorflow as tf\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotkernelsample(k, ax, xmin=-3, xmax=3):\n",
    "    xx = np.linspace(xmin, xmax, 100)[:,None]\n",
    "    K = k.compute_K_symm(xx)\n",
    "    ax.plot(xx, np.random.multivariate_normal(np.zeros(100), K, 3).T)\n",
    "    ax.set_title(k.__class__.__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplos de kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalmente, se suele suponer que un proceso gaussiano (GP) tiene media constante igual a 0 sin perder generalidad o flexibilidad. La cuestión será modelar la función kernel $k$ la cual será la encargada de aportar las características que son de esperar de la función que queremos modelar. Esta función nos dará la matriz de convarianza y, por tanto, la dependencia entre muestras. Entre las características que podemos imponer a nuestro GP será suavidad o periodicidad. **Nótese** que estas funciones kernels dependen de parámetros los cuales regularan estas propiedades.\n",
    "\n",
    "A continuación, vemos ejemplos de algunos los kernels más utilizados:\n",
    "\n",
    "** Función lineal **\n",
    "\n",
    " $$\\text{Lineal}\\quad k(x, x') = \\sigma^2 x \\cdot x'$$\n",
    "\n",
    "** Función Estática **\n",
    "\n",
    " $$\\text{White}\\quad k(x, x') = \\sigma^2\\delta_{x x'}$$\n",
    "\n",
    "** Funciones estacionarias: ** $r = \\frac{\\parallel x - x'\\parallel_2}{l}$\n",
    "\n",
    "\n",
    " $$\\text{Matern12}\\quad k(x, x') = \\sigma^2\\exp\\left(-r\\right)$$ \n",
    "\n",
    " $$\\text{Matern32}\\quad k(x, x') = \\sigma^2(1+\\sqrt{3}r)\\exp\\left(-\\sqrt{3}r\\right)$$\n",
    " \n",
    "  $$\\text{Matern52}\\quad k(x, x') = \\sigma^2(1+\\sqrt{5}r + \\frac{5}{3}r^2)\\exp\\left(-\\sqrt{5}r\\right)$$\n",
    " \n",
    " $$\\text{RBF}\\quad k(x, x') = \\sigma^2\\exp\\left(-\\frac{r^2}{2}\\right)$$\n",
    " \n",
    "** Funciones periódicas **\n",
    "\n",
    " $$\\text{Coseno}\\quad k(x, x') = \\sigma^2\\cos\\left(r^2\\right)$$\n",
    " \n",
    "  $$\\text{Periódica}\\quad k(x, x') = \\sigma^2\\exp\\left(-\\frac{\\frac{1}{p}\\sin(\\pi{\\parallel x-x'\\parallel_2^2})}{l}\\right)$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "f, axes = plt.subplots(2, 4, figsize=(12, 6), sharex=True, sharey=True)\n",
    "plotkernelsample(gpflow.kernels.Matern12(1), axes[0,0])\n",
    "plotkernelsample(gpflow.kernels.Matern32(1), axes[0,1])\n",
    "plotkernelsample(gpflow.kernels.Matern52(1), axes[0,2])\n",
    "plotkernelsample(gpflow.kernels.RBF(1), axes[0,3])\n",
    "plotkernelsample(gpflow.kernels.White(1), axes[1,0])\n",
    "plotkernelsample(gpflow.kernels.Linear(1), axes[1,1])\n",
    "plotkernelsample(gpflow.kernels.Cosine(1), axes[1,2])\n",
    "plotkernelsample(gpflow.kernels.Periodic(1), axes[1,3])\n",
    "axes[0,0].set_ylim(-3, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel RBF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El kernel más utilizado es el Radial Basis Function (RBF). Este aporta suavidad a la función lo cual será algo deseable normalmente. Además tiene suficiente flexibilidad para poder aproximar diversas funciones.\n",
    "\n",
    "En el siguiente script, prueba distintos valores de escala ($sc$) y varianza ($var$) para ver en qué afecta a la función resultante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 1\n",
    "sc = 10\n",
    "np.random.seed(100)\n",
    "k = gpflow.kernels.RBF(input_dim = 1, lengthscales = sc, variance = var)\n",
    "\n",
    "f, axes = plt.subplots(1 , 1, figsize=(12, 6), sharex=True, sharey=True)\n",
    "plotkernelsample(gpflow.kernels.RBF(input_dim = 1, lengthscales = sc, variance = var), axes)\n",
    "\n",
    "x_title = 'k(x,y) = {} exp [- {} ||x - y ||$^2$]'.format(var, 1/sc)\n",
    "axes.set_xlabel(x_title)\n",
    "\n",
    "\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta:** ¿Cómo afecta la escala y la varianza a las funciones resultantes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construcción de nuevos kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de estos kernels vistos se pueden construir nuevos. Una referencia de esto la podemos encontrar en el [Kernel Cookbook](https://www.cs.toronto.edu/~duvenaud/cookbook/). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suma de kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = gpflow.kernels.RBF(1) + gpflow.kernels.White(1, 1e-3)\n",
    "np.random.seed(100)\n",
    "f, axes = plt.subplots(1 , 1, figsize=(12, 6), sharex=True, sharey=True)\n",
    "plotkernelsample(k, axes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta:** ¿Qué pasaría si sumaramos un kernel periódico con uno lineal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiplicación de kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = gpflow.kernels.Linear(1) * gpflow.kernels.Linear(1)\n",
    "np.random.seed(100)\n",
    "f, axes = plt.subplots(1 , 1, figsize=(12, 6), sharex=True, sharey=True)\n",
    "plotkernelsample(k, axes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta:** ¿Qué pasaría si multiplicaramos 3 kernels lineales?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernels en varias dimensiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensiones activas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos aplicar determinados kernels en dimensiones específicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k1 = gpflow.kernels.Linear(1, active_dims=[0])\n",
    "k2 = gpflow.kernels.Matern52(1, active_dims=[1])\n",
    "k = k1 + k2\n",
    "k.as_pandas_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic relevance determination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto significa que estamos poniendo un parámetro de escala $l$ distinto en cada dimensión. Esto hará que no todas las dimensiones contribuyan por igual. Cuando estimemos estos parámetros de escalas nos indicará la relevancia de cada dimensión ya que valores más altas denotan una dependencia más alta en esa dimensión respecto de la variable objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k1 = gpflow.kernels.RBF(5, ARD = True)\n",
    "k1.as_pandas_table()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
